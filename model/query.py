from dotenv import load_dotenv
from typing import List
from const import get_openai_client, get_embedding_model
import os
import ast

load_dotenv()

class COTExtractor():
    
    def __init__(self):
        self.model_name = os.getenv("PROCESSING_MODEL")
        self.prompt_id = os.getenv("COT_PROMPT_ID")
            
    def generate_cot(self, input: str) -> List:
        """
        Generates a response using the model and COT prompt.
        
        Args:
            input (str): The input text/query.
        
        Returns:
            cot_list (str): The list of chain of thought questions generated by the model.
        """
        client = get_openai_client()
        
        response = client.responses.create(
            model = self.model_name,
            prompt = {
                "id":self.prompt_id
            },
            input = input
        )
        
        print(response)
        
        cot_list_string = response.output[0].content[0].text
        cot_list = ast.literal_eval(cot_list_string)
        return cot_list